{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered JSON with random selection saved to C:\\Users\\Devix\\OneDrive - University of Gothenburg\\THESIS\\MultiWozDataset\\test\\filtered_file.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "# File paths\n",
    "file_path_1 = 'MultiWozDataset\\\\test\\\\dialogues_001.json'\n",
    "file_path_2 = 'MultiWozDataset\\\\test\\\\dialogues_002.json'\n",
    "filtered_file_path = 'MultiWozDataset\\\\test\\\\filtered_file.json'\n",
    "\n",
    "# Function to read and combine JSON files\n",
    "def read_and_combine(file_path_1, file_path_2):\n",
    "    with open(file_path_1, 'r') as file:\n",
    "        data1 = json.load(file)\n",
    "    with open(file_path_2, 'r') as file:\n",
    "        data2 = json.load(file)\n",
    "    return data1 + data2\n",
    "\n",
    "# Filter dialogues by service\n",
    "def filter_by_service(data, service):\n",
    "    return [dialogue for dialogue in data if sorted(dialogue[\"services\"]) == [service]]\n",
    "\n",
    "# Randomly select n dialogues\n",
    "def random_select(data, n):\n",
    "    if len(data) >= n:\n",
    "        return random.sample(data, n)\n",
    "    else:\n",
    "        return data \n",
    "\n",
    "# Read and combine the files\n",
    "combined_data = read_and_combine(file_path_1, file_path_2)\n",
    "\n",
    "# Filter combined data for 'train' only and 'hotel' only, then randomly select 100 from each to test\n",
    "filtered_data_train = random_select(filter_by_service(combined_data, \"train\"), 100)\n",
    "filtered_data_hotel = random_select(filter_by_service(combined_data, \"hotel\"), 100)\n",
    "\n",
    "# Combine the randomly selected dialogues\n",
    "filtered_data_combined = filtered_data_train + filtered_data_hotel\n",
    "\n",
    "# Write the filtered content to a new file\n",
    "with open(filtered_file_path, 'w') as file:\n",
    "    json.dump(filtered_data_combined, file, indent=2)\n",
    "\n",
    "print(f\"Filtered JSON with random selection saved to {filtered_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of 'train' dialogues: 366\n",
      "Number of 'hotel' dialogues: 400\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "# Path to the filtered output file\n",
    "filtered_file_path = 'combined_train.json'\n",
    "\n",
    "# Function to count dialogues by type\n",
    "def count_dialogues_by_type(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        dialogues = json.load(file)\n",
    "\n",
    "    # Initialize counters\n",
    "    count_train = 0\n",
    "    count_hotel = 0\n",
    "\n",
    "    # Count each type\n",
    "    for dialogue in dialogues:\n",
    "        if \"train\" in dialogue[\"services\"]:\n",
    "            count_train += 1\n",
    "        elif \"hotel\" in dialogue[\"services\"]:\n",
    "            count_hotel += 1\n",
    "\n",
    "    return count_train, count_hotel\n",
    "\n",
    "# Get the counts\n",
    "count_train, count_hotel = count_dialogues_by_type(filtered_file_path)\n",
    "\n",
    "# Output the counts\n",
    "print(f\"Number of 'train' dialogues: {count_train}\")\n",
    "print(f\"Number of 'hotel' dialogues: {count_hotel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Path to the filtered output file\n",
    "filtered_file_path = 'multiwoz_model_data\\\\filtered_file_test.json'  # Adjust to your file path'  # Adjust to your file path'  # Adjust to your desired output path\n",
    "\n",
    "# Function to count dialogues by type\n",
    "def count_dialogues_by_type(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        dialogues = json.load(file)\n",
    "\n",
    "    # Initialize counters\n",
    "    count_train = 0\n",
    "    count_hotel = 0\n",
    "\n",
    "    # Count each type\n",
    "    for dialogue in dialogues:\n",
    "        if \"train\" in dialogue[\"services\"]:\n",
    "            count_train += 1\n",
    "        elif \"hotel\" in dialogue[\"services\"]:\n",
    "            count_hotel += 1\n",
    "\n",
    "    return count_train, count_hotel\n",
    "\n",
    "# Get the counts\n",
    "count_train, count_hotel = count_dialogues_by_type(filtered_file_path)\n",
    "\n",
    "# Output the counts\n",
    "print(f\"Number of 'train' dialogues: {count_train}\")\n",
    "print(f\"Number of 'hotel' dialogues: {count_hotel}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered JSON with random selection saved to C:\\Users\\Devix\\OneDrive - University of Gothenburg\\THESIS\\MultiWozDataset\\train\\filtered_file.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import glob\n",
    "import random\n",
    "\n",
    "# Directory path to the JSON files\n",
    "directory_path = 'MultiWozDataset\\\\train\\\\*.json'\n",
    "\n",
    "# Output file path\n",
    "filtered_file_path = 'MultiWozDataset\\\\train\\\\filtered_file.json'\n",
    "\n",
    "# Function to read JSON files and combine data\n",
    "def read_and_combine(directory_path):\n",
    "    combined_data = []\n",
    "    for file_path in glob.glob(directory_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            combined_data.extend(json.load(file))\n",
    "    return combined_data\n",
    "\n",
    "# Function to filter dialogues by services containing only the specified service\n",
    "def filter_by_service(data, services):\n",
    "    return [dialogue for dialogue in data if sorted(dialogue[\"services\"]) == sorted(services)]\n",
    "\n",
    "# Function to randomly select n dialogues\n",
    "def random_select(data, n):\n",
    "    return random.sample(data, min(n, len(data)))\n",
    "\n",
    "# Read and combine the files\n",
    "combined_data = read_and_combine(directory_path)\n",
    "\n",
    "# Filter combined data for 'train' only and 'hotel' only\n",
    "filtered_data_train = filter_by_service(combined_data, [\"train\"])\n",
    "filtered_data_hotel = filter_by_service(combined_data, [\"hotel\"])\n",
    "\n",
    "\n",
    "random_data_train = random_select(filtered_data_train, 467)\n",
    "random_data_hotel = random_select(filtered_data_hotel, 429)\n",
    "\n",
    "# Combine the randomly selected dialogues\n",
    "filtered_data_combined = random_data_train + random_data_hotel\n",
    "\n",
    "# Write the filtered content to a new file\n",
    "with open(filtered_file_path, 'w') as file:\n",
    "    json.dump(filtered_data_combined, file, indent=2)\n",
    "\n",
    "print(f\"Filtered JSON with random selection saved to {filtered_file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel dialogues saved to filtered_files_hotel.json\n",
      "Train dialogues saved to filtered_files_train_output.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# File paths\n",
    "file_test = 'MultiWozDataset\\\\code\\\\multiwoz_model_data\\\\filtered_file_train.json'  \n",
    "file_train = 'MultiWozDataset\\\\code\\\\multiwoz_model_data\\\\filtered_file_test.json'  \n",
    "file_hotel_output = 'filtered_files_hotel.json'  \n",
    "file_train_output = 'filtered_files_train_output.json'  \n",
    "\n",
    "# Read the content of the files\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return json.load(file)\n",
    "\n",
    "# Combine the content\n",
    "data_test = read_file(file_test)\n",
    "data_train = read_file(file_train)\n",
    "combined_data = data_test + data_train\n",
    "\n",
    "# Split the content\n",
    "hotel_dialogues = [dialogue for dialogue in combined_data if \"hotel\" in dialogue[\"services\"]]\n",
    "train_dialogues = [dialogue for dialogue in combined_data if \"train\" in dialogue[\"services\"]]\n",
    "\n",
    "# Save the split content into separate files\n",
    "def write_file(file_path, data):\n",
    "    with open(file_path, 'w') as file:\n",
    "        json.dump(data, file, indent=2)\n",
    "\n",
    "write_file(file_hotel_output, hotel_dialogues)\n",
    "write_file(file_train_output, train_dialogues)\n",
    "\n",
    "print(f\"Hotel dialogues saved to {file_hotel_output}\")\n",
    "print(f\"Train dialogues saved to {file_train_output}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hotel train dialogues saved to filtered_files_hotel_train.json\n",
      "Hotel test dialogues saved to filtered_files_hotel_test.json\n",
      "Hotel validate dialogues saved to filtered_files_hotel_validate.json\n",
      "Train train dialogues saved to filtered_files_train_output_train.json\n",
      "Train test dialogues saved to filtered_files_train_output_test.json\n",
      "Train validate dialogues saved to filtered_files_train_output_validate.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import random\n",
    "\n",
    "def split_data(file_path, train_split=0.80, test_split=0.15, validate_split=0.05):\n",
    "    # Make sure the splits add up to 1\n",
    "    assert train_split + test_split + validate_split == 1\n",
    "    \n",
    "    # Read the data\n",
    "    with open(file_path, 'r') as file:\n",
    "        data = json.load(file)\n",
    "    \n",
    "    # Shuffle the data to ensure randomness\n",
    "    random.shuffle(data)\n",
    "    \n",
    "    # Calculate split sizes\n",
    "    total_dialogues = len(data)\n",
    "    train_size = int(train_split * total_dialogues)\n",
    "    test_size = int(test_split * total_dialogues)\n",
    "    \n",
    "    # Split the data\n",
    "    train_data = data[:train_size]\n",
    "    test_data = data[train_size:train_size + test_size]\n",
    "    validate_data = data[train_size + test_size:]\n",
    "    \n",
    "    return train_data, test_data, validate_data\n",
    "\n",
    "def save_data(base_file_path, train_data, test_data, validate_data):\n",
    "    # Save training data\n",
    "    train_file_path = base_file_path + \"_train.json\"\n",
    "    with open(train_file_path, 'w') as file:\n",
    "        json.dump(train_data, file, indent=2)\n",
    "        \n",
    "    # Save testing data\n",
    "    test_file_path = base_file_path + \"_test.json\"\n",
    "    with open(test_file_path, 'w') as file:\n",
    "        json.dump(test_data, file, indent=2)\n",
    "        \n",
    "    # Save validation data\n",
    "    validate_file_path = base_file_path + \"_validate.json\"\n",
    "    with open(validate_file_path, 'w') as file:\n",
    "        json.dump(validate_data, file, indent=2)\n",
    "    \n",
    "    return train_file_path, test_file_path, validate_file_path\n",
    "\n",
    "# Paths to the source files\n",
    "file_hotel = 'filtered_files_hotel.json'\n",
    "file_train_dialogues = 'filtered_files_train_output.json' \n",
    "\n",
    "# Split the hotel data\n",
    "hotel_train, hotel_test, hotel_validate = split_data(file_hotel)\n",
    "# Save the hotel splits\n",
    "hotel_train_path, hotel_test_path, hotel_validate_path = save_data(file_hotel.replace('.json', ''), hotel_train, hotel_test, hotel_validate)\n",
    "\n",
    "# Split the train dialogues data\n",
    "train_dialogues_train, train_dialogues_test, train_dialogues_validate = split_data(file_train_dialogues)\n",
    "# Save the train dialogues splits\n",
    "train_dialogues_train_path, train_dialogues_test_path, train_dialogues_validate_path = save_data(file_train_dialogues.replace('.json', ''), train_dialogues_train, train_dialogues_test, train_dialogues_validate)\n",
    "\n",
    "print(f\"Hotel train dialogues saved to {hotel_train_path}\")\n",
    "print(f\"Hotel test dialogues saved to {hotel_test_path}\")\n",
    "print(f\"Hotel validate dialogues saved to {hotel_validate_path}\")\n",
    "print(f\"Train train dialogues saved to {train_dialogues_train_path}\")\n",
    "print(f\"Train test dialogues saved to {train_dialogues_test_path}\")\n",
    "print(f\"Train validate dialogues saved to {train_dialogues_validate_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined file saved to combined_train.json\n",
      "Combined file saved to combined_test.json\n",
      "Combined file saved to combined_validate.json\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def combine_files(file_path_1, file_path_2, output_file_path):\n",
    "    # Read the first file\n",
    "    with open(file_path_1, 'r') as file:\n",
    "        data_1 = json.load(file)\n",
    "    \n",
    "    # Read the second file\n",
    "    with open(file_path_2, 'r') as file:\n",
    "        data_2 = json.load(file)\n",
    "    \n",
    "    # Combine the data\n",
    "    combined_data = data_1 + data_2\n",
    "    \n",
    "    # Write the combined data to the output file\n",
    "    with open(output_file_path, 'w') as file:\n",
    "        json.dump(combined_data, file, indent=2)\n",
    "    \n",
    "    print(f\"Combined file saved to {output_file_path}\")\n",
    "\n",
    "# File paths\n",
    "base_file_path = ''\n",
    "\n",
    "# Combine train files\n",
    "combine_files(base_file_path + 'filtered_files_hotel_train.json',\n",
    "              base_file_path + 'filtered_files_train_output_train.json',\n",
    "              base_file_path + 'combined_train.json')\n",
    "\n",
    "# Combine test files\n",
    "combine_files(base_file_path + 'filtered_files_hotel_test.json',\n",
    "              base_file_path + 'filtered_files_train_output_test.json',\n",
    "              base_file_path + 'combined_test.json')\n",
    "\n",
    "# Combine validation files\n",
    "combine_files(base_file_path + 'filtered_files_hotel_validate.json',\n",
    "              base_file_path + 'filtered_files_train_output_validate.json',\n",
    "              base_file_path + 'combined_validate.json')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
